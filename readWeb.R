# webscraping:
# programmatically extracting data from the HTML code

# getting data off webpages - readLines()
# open connection to url and read
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode <- readLines(con)
close(con)
## too long to read...
htmlCode

## use XML
library(XML)
## Parting with XML
page.url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(page.url, useInternalNodes=T)
## look for the node title
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)

## GET from httr package
library(httr); html2 <- GET(page.url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)


## accessing websites with passwords
pg1 <- GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg2 <- GET("http://httpbin.org/basic-auth/user/passwd"
           , authenticate("user","passwd"))
pg2
names(pg1)
names(pg2)
google <- handle("http://google.com")
pg1 <- GET(handle=google
           ,path="/")
pg2 <- GET(handle=google
           ,path="search")
pg2
